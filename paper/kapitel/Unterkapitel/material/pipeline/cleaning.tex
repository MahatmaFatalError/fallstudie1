\subsection{Data Cleaning}
\label{subsec:cleaning}
The quality of data can be described in many dimensions like \eg{} the trustworthiness of the data source, the consistency of the data,
or their accuracy as well as their topicality\cite{QD15}.
Just with very unstructured data, as in our case the collected dishes from the web page speisekarte.de, the cleaning of the data is
inevitable to get a good and accurate analysis result.
However, even with supposedly good data sources such as \acp{API}, there may be errors in the data.
such as \eg{} the mixing of different languages or the lack of information.
Differences in data quality can also occur in the process of data collection.
\newline
The following paragraphs explains the measures conducted to clean up the collected data.
\paragraph{Review Count Cleaning:} \code{NULL} values of review\_count are substituted by the number 0.
\paragraph{Address Cleaning}
If there were restaurants without a valid address the \ylp{} \ac{API} was addressed again to find the restaurant's address.
If still no city or postcode is found, this restaurant gets deleted for the reasons of simplicity, since a restaurant without a postcode or city has no use for the subsequent analysis.
\paragraph{Price Range Cleaning}
In the price\_range attribute there were occasional occuring \code{NULL} values which possibly could be filled when addressing the \ylp{} \ac{API} a second time.
If this was not the case, the \code{NULL} values were filled with the mode of the price\_range from the current city.
\paragraph{City Cleaning}
Despite the fact that the \code{city} attribute of a restaurant always came from Yelp it came to a mixture of the German and English language,
so we translated the english names in its german counterparts manually.
Furthermore, the German city ''Frankfurt am Main'' was available in different spellings.
However, this could be fixed with a simple \ac{SQL} statement.
\paragraph{Buying Power Cleaning}
The data source found for acquiring the buying\_power for various german cities unfortunately contained not the buying\_power for all german cities.
We solved this isssue by replacing the missing buying\_power with the average buying\_power in Germany in order to be able to carry out at least a rough analysis.
\paragraph{Average Purchase Price Cleaning}
Also with the average purchase price of a restaurant per m\textsuperscript{2} the original data source did not include all cities of Germany and therefore
some \code{NULL} values remained in the database.
These have been replaced with the germany-wide average.
\paragraph{Menu Item Cleaning}
Although most of the cleaning took place after the persistence of the data in the database, the various dishes on a menu had to be
cleaned before it was written to the database.
By scraping these data directly from the web, it often happened that they were not only semantically wrong, but also containing only
special characters or an empty string.
Especially these entries without any informational content had to be removed before they were stored in the database.
This was done with several algorithms from the area of \textit{Text Preprocessing}\footnote{Please refer to \fullref{subsec:review} to learn more about \textit{Text Preprocessing}}.
