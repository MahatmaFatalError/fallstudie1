\subsection{Review Analysis}
\label{subsec:review}
As mentioned in \fullref{subsec:usecase} it is not only the goal to propose one or more cities for the opening of a restaurant,
 but also to give recommendations for qualitative characteristics of a restaurant.
\newline
For this purpose, the available reviews of a city are analyzed with the help of \ac{NLP}.
\ac{NLP} is the computer-based attempt to support any text with the help of a set of technologies and linguistic knowledge.\cite{Liddy01}
The goal of \ac{NLP} is to achieve a human-like processing of language.\cite{Liddy01}
The frequency of a certain word within the reviews - and thus also the importance of the word - can be expressed by \ac{TFIDF}.
This \ac{KPI} consists of a total of two calculations.
First the \ac{TF} is calculated.
This indicates how often a single word appears within a given document.
Mathematically this means:
\newline
\begin{equation}
  tf\textsubscript{i,j} = \frac{n\textsubscript{i,j}}{\sum_{k} n\textsubscript{i,j}}
	\label{eq:tf}
\end{equation}
Since in the pure term-frequency the totality of documents is disregarded, there is the \ac{IDF} measure.
The \ac{IDF} measure indicates how often a single word occurs within the body of documents.\footnote{The totality of all documents}
It is given by the equation below.
\newline
\begin{equation}
  idf(w) = \log \frac{N}{df\textsubscript{t}}
	\label{eq:tf}
\end{equation}
Where df\textsubscript{t} is the number of documents containing the term t and N is the total number of documents in the corpus.
The factor of these two figures then forms the \ac{TFIDF} measure.\cite{droid18}
\newline
For our purposes not every single word of an yelp review is of importance.
To filter words with a low information content from an existing text, there are several methods from the area of \textit{Text Preprocessing}.
The following methods were used to improve the information density of restaurant reviews in order to calculate a meaningful \ac{TFIDF}.
\paragraph{Tokenization}
Tokenization is the process to divide a coherent sentence into single pieces, called tokens.
Beside the subdivision into single pieces, the so called stopwords and the punctuation is removed.
After executing Tokenization on this exemplary sentence below
\begin{center}
  \textitbf{Hello, my name is Bob!}
\end{center}
a list of three words
\begin{center}
  \textitbf{Hello} \textitbf{name} and \textitbf{Bob}
\end{center}
will remain.\newline
The sentence structure and the grammatical correctness of the sentence are lost, but the words with a high expressiveness remain.
\paragraph{Stemming}
\paragraph{\acs{POS} Tagging}
